{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minerl\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "from logging import getLogger\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "logger = getLogger(__name__)\n",
    "# import logging\n",
    "\n",
    "# Download Single experiment\n",
    "# minerl.data.download('/home/sapanostic/Courses/WPI_RL/Project/minerl_data/',experiment='MineRLObtainDiamond-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below line to see the logging process\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "env = gym.make('MineRLNavigateDense-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "The obs variable will be a dictionary containing the following observations returned by the environment. In the case of the MineRLNavigate-v0 environment, three observations are returned:\n",
    "\n",
    "1) pov: an RGB image of the agent’s first person perspective (64,64,3)\n",
    "\n",
    "2) compassAngle, a float giving the angle of the agent to its (approximate) target\n",
    "\n",
    "3) inventory, a dictionary containing the amount of 'dirt' blocks in the agent’s inventory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict(attack:Discrete(2), back:Discrete(2), camera:Box(2,), forward:Discrete(2), jump:Discrete(2), left:Discrete(2), place:Enum(none,dirt), right:Discrete(2), sneak:Discrete(2), sprint:Discrete(2))\n",
      "number of objects in Observation Dict:  3\n",
      "First person view (pov) image size:  (64, 64, 3)\n",
      "Inventory:  {'dirt': 0}\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(\"number of objects in Observation Dict: \", len(obs))\n",
    "print(\"First person view (pov) image size: \", np.shape(obs['pov']))\n",
    "print(\"Inventory: \", obs['inventory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerialDiscreteActionWrapper(gym.ActionWrapper):\n",
    "    \"\"\"Convert MineRL env's `Dict` action space as a serial discrete action space.\n",
    "\n",
    "    The term \"serial\" means that this wrapper can only push one key at each step.\n",
    "    \"attack\" action will be alwarys triggered.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env\n",
    "        Wrapping gym environment.\n",
    "    always_keys\n",
    "        List of action keys, which should be always pressed throughout interaction with environment.\n",
    "        If specified, the \"noop\" action is also affected.\n",
    "    reverse_keys\n",
    "        List of action keys, which should be always pressed but can be turn off via action.\n",
    "        If specified, the \"noop\" action is also affected.\n",
    "    exclude_keys\n",
    "        List of action keys, which should be ignored for discretizing action space.\n",
    "    exclude_noop\n",
    "        The \"noop\" will be excluded from discrete action list.\n",
    "    num_camera_discretize\n",
    "        Number of discretization of yaw control (must be odd).\n",
    "    allow_pitch\n",
    "        If specified, this wrapper appends commands to control pitch.\n",
    "    max_camera_range\n",
    "        Maximum value of yaw control.\n",
    "    \"\"\"\n",
    "\n",
    "    BINARY_KEYS = ['forward', 'back', 'left', 'right', 'jump', 'sneak', 'sprint', 'attack']\n",
    "\n",
    "    def __init__(self, env, always_keys=None, reverse_keys=None, exclude_keys=None, exclude_noop=False,\n",
    "                 num_camera_discretize=3, allow_pitch=False,\n",
    "                 max_camera_range=10):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self.always_keys = [] if always_keys is None else always_keys\n",
    "        self.reverse_keys = [] if reverse_keys is None else reverse_keys\n",
    "        self.exclude_keys = [] if exclude_keys is None else exclude_keys\n",
    "        if len(set(self.always_keys) | set(self.reverse_keys) | set(self.exclude_keys)) != \\\n",
    "                len(self.always_keys) + len(self.reverse_keys) + len(self.exclude_keys):\n",
    "            raise ValueError('always_keys ({}) or reverse_keys ({}) or exclude_keys ({}) intersect each other.'.format(\n",
    "                self.always_keys, self.reverse_keys, self.exclude_keys))\n",
    "        self.exclude_noop = exclude_noop\n",
    "\n",
    "        self.wrapping_action_space = self.env.action_space\n",
    "        self.num_camera_discretize = num_camera_discretize\n",
    "        self._noop_template = OrderedDict([\n",
    "            ('forward', 0),\n",
    "            ('back', 0),\n",
    "            ('left', 0),\n",
    "            ('right', 0),\n",
    "            ('jump', 0),\n",
    "            ('sneak', 0),\n",
    "            ('sprint', 0),\n",
    "            ('attack', 0),\n",
    "            ('camera', np.zeros((2, ), dtype=np.float32)),\n",
    "            # 'none', 'dirt' (Obtain*:)+ 'stone', 'cobblestone', 'crafting_table', 'furnace', 'torch'\n",
    "            ('place', 0),\n",
    "            # (Obtain* tasks only) 'none', 'wooden_axe', 'wooden_pickaxe', 'stone_axe', 'stone_pickaxe', 'iron_axe', 'iron_pickaxe'\n",
    "            ('equip', 0),\n",
    "            # (Obtain* tasks only) 'none', 'torch', 'stick', 'planks', 'crafting_table'\n",
    "            ('craft', 0),\n",
    "            # (Obtain* tasks only) 'none', 'wooden_axe', 'wooden_pickaxe', 'stone_axe', 'stone_pickaxe', 'iron_axe', 'iron_pickaxe', 'furnace'\n",
    "            ('nearbyCraft', 0),\n",
    "            # (Obtain* tasks only) 'none', 'iron_ingot', 'coal'\n",
    "            ('nearbySmelt', 0),\n",
    "        ])\n",
    "        for key, space in self.wrapping_action_space.spaces.items():\n",
    "            if key not in self._noop_template:\n",
    "                raise ValueError('Unknown action name: {}'.format(key))\n",
    "\n",
    "        # get noop\n",
    "        self.noop = copy.deepcopy(self._noop_template)\n",
    "        for key in self._noop_template:\n",
    "            if key not in self.wrapping_action_space.spaces:\n",
    "                del self.noop[key]\n",
    "\n",
    "        # check&set always_keys\n",
    "        for key in self.always_keys:\n",
    "            if key not in self.BINARY_KEYS:\n",
    "                raise ValueError('{} is not allowed for `always_keys`.'.format(key))\n",
    "            self.noop[key] = 1\n",
    "        logger.info('always pressing keys: {}'.format(self.always_keys))\n",
    "        # check&set reverse_keys\n",
    "        for key in self.reverse_keys:\n",
    "            if key not in self.BINARY_KEYS:\n",
    "                raise ValueError('{} is not allowed for `reverse_keys`.'.format(key))\n",
    "            self.noop[key] = 1\n",
    "        logger.info('reversed pressing keys: {}'.format(self.reverse_keys))\n",
    "        # check exclude_keys\n",
    "        for key in self.exclude_keys:\n",
    "            if key not in self.noop:\n",
    "                raise ValueError('unknown exclude_keys: {}'.format(key))\n",
    "        logger.info('always ignored keys: {}'.format(self.exclude_keys))\n",
    "\n",
    "        # get each discrete action\n",
    "        self._actions = [self.noop]\n",
    "        for key in self.noop:\n",
    "            if key in self.always_keys or key in self.exclude_keys:\n",
    "                continue\n",
    "            if key in self.BINARY_KEYS:\n",
    "                # action candidate : {1}  (0 is ignored because it is for noop), or {0} when `reverse_keys`.\n",
    "                op = copy.deepcopy(self.noop)\n",
    "                if key in self.reverse_keys:\n",
    "                    op[key] = 0\n",
    "                else:\n",
    "                    op[key] = 1\n",
    "                self._actions.append(op)\n",
    "            elif key == 'camera':\n",
    "                # action candidate : {[0, -max_camera_range], [0, -max_camera_range + delta_range], ..., [0, max_camera_range]}\n",
    "                # ([0, 0] is excluded)\n",
    "                delta_range = max_camera_range * 2 / (self.num_camera_discretize - 1)\n",
    "                if self.num_camera_discretize % 2 == 0:\n",
    "                    raise ValueError('Number of camera discretization must be odd.')\n",
    "             \n",
    "                for i in range(self.num_camera_discretize):\n",
    "                    op = copy.deepcopy(self.noop)\n",
    "                    if i < self.num_camera_discretize // 2:\n",
    "                        op[key] = np.array([0, -max_camera_range + delta_range * i], dtype=np.float32)\n",
    "                    elif i > self.num_camera_discretize // 2:\n",
    "                        op[key] = np.array([0, -max_camera_range + delta_range * (i - 1)], dtype=np.float32)\n",
    "                    elif i == self.num_camera_discretize // 2:\n",
    "                        op[key] = np.array([0, -max_camera_range + delta_range * (i + 1)], dtype=np.float32)                            \n",
    "                    else:\n",
    "                        continue\n",
    "                    self._actions.append(op)\n",
    "\n",
    "                if allow_pitch:\n",
    "                    for i in range(self.num_camera_discretize):\n",
    "                        op = copy.deepcopy(self.noop)\n",
    "                        if i < self.num_camera_discretize // 2:\n",
    "                            op[key] = np.array([-max_camera_range + delta_range * i, 0], dtype=np.float32)\n",
    "                        elif i > self.num_camera_discretize // 2:\n",
    "                            op[key] = np.array([-max_camera_range + delta_range * (i - 1), 0], dtype=np.float32)\n",
    "                        else:\n",
    "                            continue\n",
    "                        self._actions.append(op)\n",
    "\n",
    "            elif key in {'place', 'equip', 'craft', 'nearbyCraft', 'nearbySmelt'}:\n",
    "                # action candidate : {1, 2, ..., len(space)-1}  (0 is ignored because it is for noop)\n",
    "                for a in range(1, self.wrapping_action_space.spaces[key].n):\n",
    "                    op = copy.deepcopy(self.noop)\n",
    "                    op[key] = a\n",
    "                    self._actions.append(op)\n",
    "        if self.exclude_noop:\n",
    "            del self._actions[0]\n",
    "\n",
    "        n = len(self._actions)\n",
    "        self.action_space = gym.spaces.Discrete(n)\n",
    "        logger.info('{} is converted to {}.'.format(self.wrapping_action_space, self.action_space))\n",
    "\n",
    "    def action(self, action):\n",
    "        if not self.action_space.contains(action):\n",
    "            raise ValueError('action {} is invalid for {}'.format(action, self.action_space))\n",
    "\n",
    "        original_space_action = self._actions[action]\n",
    "        logger.debug('discrete action {} -> original action {}'.format(action, original_space_action))\n",
    "        return original_space_action\n",
    "    \n",
    "    def sample(self):\n",
    "        rand_action = np.random.choice(np.array(range(self.action_space.n)),1)\n",
    "        return rand_action[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoVWithCompassAngleWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"Take 'pov' value (current game display) and concatenate compass angle information with it, as a new channel of image;\n",
    "    resulting image has RGB+compass (or K+compass for gray-scaled image) channels.\n",
    "    \"\"\"\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "        self._compass_angle_scale = 180 / 255  # NOTE: `ScaledFloatFrame` will scale the pixel values with 255.0 later\n",
    "\n",
    "        pov_space = self.env.observation_space.spaces['pov']\n",
    "        compass_angle_space = self.env.observation_space.spaces['compassAngle']\n",
    "\n",
    "        low = self.observation({'pov': pov_space.low, 'compassAngle': compass_angle_space.low})\n",
    "        high = self.observation({'pov': pov_space.high, 'compassAngle': compass_angle_space.high})\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(low=low, high=high)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        pov = observation['pov']\n",
    "        compass_scaled = observation['compassAngle'] / self._compass_angle_scale\n",
    "        compass_channel = np.ones(shape=list(pov.shape[:-1]) + [1], dtype=pov.dtype) * compass_scaled\n",
    "        return np.concatenate([pov, compass_channel], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space:  7\n",
      "observation_space:  (64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "always_keys = ['forward', 'attack', 'jump']\n",
    "exclude_keys = ['back', 'place', 'sneak']\n",
    "reverse_keys=None\n",
    "exclude_noop=False\n",
    "num_camera_discretize=3\n",
    "allow_pitch=False\n",
    "max_camera_range=10\n",
    "\n",
    "env_pov_comm = PoVWithCompassAngleWrapper(env)\n",
    "\n",
    "env_serial = SerialDiscreteActionWrapper(env_pov_comm, always_keys, reverse_keys, exclude_keys, exclude_noop,\n",
    "                 num_camera_discretize, allow_pitch,\n",
    "                 max_camera_range)\n",
    "\n",
    "print('Action Space: ', env_serial.action_space.n)\n",
    "print('observation_space: ', env_serial.observation_space.shape)\n",
    "\n",
    "# print(env_serial.noop)\n",
    "# print(env_serial.action(6))\n",
    "\n",
    "#0:Noop \n",
    "#1:left \n",
    "#2:right \n",
    "#3:sprint \n",
    "#4:Camera[0,-10] \n",
    "#5:Camera[0,10]\n",
    "#5:Camera[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-01eb7019a853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnX+wXMV1579nfs+8308SQgiw2AWD8ToIrwr/gA0YAss6cchWXN7Yzhb2KqtKrZPgiqkAu5Wfu6m1a2vjOKnYWSXYULV2bMeJLYryOiZak1QqWYywMQaEkAzYCCM9/Xi/f8zPs3/MfdOn+8297859d+68p3s+VSr1ne7pPnPn9dxz+pw+TcwMRVHSRWbQAiiKkjw68RUlhejEV5QUohNfUVKITnxFSSE68RUlhejEV5QUsqGJT0R3EtExIjpBRPfHJZSiKP2FogbwEFEWwIsAbgdwEsCTAN7PzM/HJ56iKP0gt4H33gDgBDO/BABE9EUAdwHwnfjDY9t5cueernWBPz+bPLhwk4vXFQpbGfLDbYV7EPiZNyM9CLza9PzpV7Awe3bdd25k4u8G8Kq4PgngbUFvmNy5Bx/7oyNd68JO/LB/YEGKTJJjRR07Kn5dZByjjgL+NGRb+dkC7yn7X0eNCiffi4B2Qf2FbLim2aDGjjDx/+ev7QvVvu+Le0R0gIiOENGRhdkz/R5OUZQQbOSJ/xqAy8T1pd5rFsx8EMBBALj8jfu489PkPAUCtUtRSWGfyO6vJXevCjtW0Hjur3nQEy6CFt0Tvg8J936TbxVaLVHXw1M+bF2iRH3Kb7RdhKd1LwNs1GzZyBP/SQBXEdEVRFQA8AsAHtmgPIqiJEDkJz4zN4joVwD8DYAsgM8y83OxSaYoSt/YiKoPZv46gK/HJIuiKAmxoYkfhY6JH9IGd6pCG8lr+vB5X+ixEHF9oRdbt98LAAJpx7v2qJ992m+zPexqei/2bSRbOKoBHbPXoKfP2aPMGrKrKClEJ76ipJDEVf1VwqribltZ1Q83WhzadpSx1rSNqm76DOjemyDV0Pc+uq9vFpedIPEgHepaDO6jz2OFQZ/4ipJCdOIrSgrRia8oKWRw7jyf14Hwrr41fcgw1CB7P2S7tW8UxRhCh/tCDLGncYTbxr0TLo7+4razg9rGsoYQcqwo6BNfUVKITnxFSSHJu/M8fSVo51scUXdhXX1B7cK623r6LN3FGChBOxStdq3ur8dGRF2216i1nofehC67XkyJbugTX1FSiE58RUkhm2aTjqXNB0XuRYjwW6/Oahew4h9LVF/I/sMSVQ7LpIk7C8WawaK9Lexqd+g+opoSMfSfpCkRBn3iK0oK0YmvKClEJ76ipJDNsztP1oV1sfXiios56i4o0jB0/zEQRzRX0M69WJJmxhzGF4ebK7CPXmz1mPuPLEeP6BNfUVKITnxFSSHJu/M8HWWNuy1APY5j842fah5HBOFaQUL230MikX6yRm0MMJl8mvVHDlnX5+i80Gp1RPU79v43uIFHn/iKkkJ04itKCtGJrygpZNO48+LIhhnFJdiLK85v6K2wA68fJBliHEQU27enNYMIdndUl2Mcob1hWPeJT0SfJaIpInpWvDZJRI8R0XHv/4kNyqEoSoKEUfUfAnCn89r9AA4z81UADnvXiqJsEdZV9Zn574loj/PyXQBu8coPA3gcwH3r9UXwV7GCdotZarVUxXvZ4efj6gsb4bdGjgiuQ7fPILdlWNaozpvczuhJww4bFRdWxe5HxFwMY0cyFyJEDEqiLu7tZObXvfIpADsj9qMoygDY8Ko+MzMCnjNEdICIjhDRkYXZMxsdTlGUGIi6qn+aiHYx8+tEtAvAlF9DZj4I4CAAvOGN+9Zkzu4Qd9Rd0Kq+HMsVI8iU8FHTe8rbF1L+sITdNBLEpjEX+pEQJG71PgavQd/NhRBEfeI/AuBur3w3gEMR+1EUZQCEcef9BYB/AnA1EZ0kov0APg7gdiI6DuCnvGtFUbYIYVb13+9TdVvMsiiKkhDJRu5RuN15obeE9RIyF4c7L2Qyj9CJLDZJyN9mWSfoKdrNr64PNnhSrrioY1mXIb87jdVXlBSiE19RUsjAEnEE7oBx8VHvA6Pz3O79TIQAlTTQnRfWLRdxE1AQmzE4Lw5zIbCLIDU6goo9MFW829h+coU0W9aTqxv6xFeUFKITX1FSiE58RUkhg7Pxg4iaASNCH0F2/Jou/dx5MfTRrR8/rGYxGPybZc0gsu0eVBezXd/vtYFY1hdCoE98RUkhOvEVJYUkquoTjEoSlGwjMgFmgG+ij6DovID+o0T4BXTXfTyfdqHe1ANBnzMqkbqII+ouqI+IKnskN13UPjZoEoT9c9AnvqKkEJ34ipJCEl/Vz/hs0oGfKg4nQi9AXYt9dTqG/NqBK/5BnzOg+zhI1HyI4YuJvOruU9eLByHS2H1U57vV6aq+oijrohNfUVKITnxFSSEDi9wLss9Dn6AV1gaHbRP5rRmseV/IuqBdgkHuwiAZgwg0mUPa0/1YN5AE7VD0I6xtHdndFnGHXxQbP47+gz7nRo8N1ye+oqQQnfiKkkKSjdwjIOP91IQ94gqIaAY4dWE9SkF9hCaiKRGYny+gy/CV4fAVo4cbEkWMqC67SKp4RFdZHDJGdeeFGTusCaBPfEVJITrxFSWF6MRXlBSSqI2fyQAj5XZ5ccWuk/btGvvcx/53w2GDbGQ/2z3qWkBgiHGEPgDgkm2m/OPz0fqIOLSFr5nYbx+gO1xI+zzQnRehjzjs/1j6WOd9Yeu6EeYIrcuI6FtE9DwRPUdE93ivTxLRY0R03Pt/orehFUUZFGFU/QaAjzHztQDeDuAjRHQtgPsBHGbmqwAc9q4VRdkChDk773UAr3vleSI6CmA3gLsA3OI1exjA4wDuC+qLYNSX4ZIzTsD7FpZFu7BuvwAzIKrr0K+up0i6kCrZJZOm/HqQ2h/QXyR1vhdCmhmhXakR1egoZkDUPoJcbJHNhbDmSAgzIOz32tPiHhHtAXA9gCcA7PR+FADgFICdvfSlKMrgCD3xiWgYwF8B+Cgzz8k6Zmb4/LAT0QEiOkJER2anz2xIWEVR4iHUxCeiPNqT/vPM/Nfey6eJaJdXvwvAVLf3MvNBZt7HzPvGJnbEIbOiKBtkXRufiAjAgwCOMvMfiKpHANwN4OPe/4dCjei3E0leOLrDqgvQrQp0CQbsioviOnTbtpAcuybt61PTMQ8QNTY55PpCWLuzLzZ+DO68KKG4vYTsxvo5Q97sMH78GwH8ewDfJ6Knvdf+M9oT/stEtB/ADwG8L9yQiqIMmjCr+v8A/9+R2+IVR1GUJEg0co8ZaDXbZVdVlmp1PkAq+QvkugSXqqbcctV0n4i/Nep8SDMAQWaFT3m9uqmZ7nU7x+12YaO0gswnq6oPEXlRdjm6YmT81OioanrMqrh7nQnZf6XoVqIrtXqAjD7998WdpyjKhYFOfEVJIYkn4sh5Iwap2K2Wf53VzumjIlT/lVpA/0FqekCdfJ+lypJ/u15MCfmxZZdnZu12mZD6XGDeO5/PErq/Hgi9qu9e+6jf7ucPq6b7mQ699OHWZfxU+KDIPee63ujefy7rL6P7xNZEHIqirItOfEVJITrxFSWFJJ5Xf5VAt4jbOKSNv+oqBICc04kVdRfSjnfrMiHXCShi/75GdB+SbUhDc8eoXXVmrnvdlLPWEDehXWUh7fie+oi4hlAqdJfDpSkWcNw+8lmfuj64WVfRJ76ipBCd+IqSQgam6veEj6qVXdvSEFLFXmMuhFTTpcsxsF1IcwGwTYSwu1yiutgmR/zrdox1f/2i8e6vr8fZkCZCxnkMhVXTw9bF0cea/IpShc/4t3Ndc4NGn/iKkkJ04itKCtGJrygpZGvY+FEIsNMkQaaXGzrsZ+MHrRO4fZTdnVmC2cXur8dxLLbbTI41PhSuj6hkQ9q37nfkZ5+7awFyl+ayE6rt977AsQLWGi4U9ImvKClEJ76ipJALV9WPAVflsy4D1NemiCB0zQC5E8utG/NRuZfc3IL+Q/sSeLyYo8pa5xgEdhquKh9V1Rc3PBugijfE/S7l/fu4EFX2qOgTX1FSiE58RUkhqur3AbmK7Wq5UhN11W+5kUPqysNlhEaaEjJ3Ya2xtu0qropdFEIWRNnNAce+FwHtAigX1m8DqMoeB/rEV5QUohNfUVKITnxFSSFq4w+QfuzgKuS7v170eb0bJR9b2+91Zeux7hOfiEpE9G0i+h4RPUdEv+u9fgURPUFEJ4joS0SkfxaKskUIo+pXAdzKzNcB2AvgTiJ6O4BPAPgkM18JYBrA/v6JqShKnKw78bnNgneZ9/4xgFsBfMV7/WEAP9cXCRVFiZ1Qi3tElPVOyp0C8BiAHwCYYeZV7/BJALv7I6KiKHETauIzc5OZ9wK4FMANAK4JOwARHSCiI0R0ZG76TEQxFUWJk57cecw8A+BbAN4BYJyIVr0ClwJ4zec9B5l5HzPvG53YsSFhFUWJhzCr+juIaNwrlwHcDuAo2j8A7/Wa3Q3gUL+EVBQlXsL48XcBeJiIsmj/UHyZmR8loucBfJGI/huA7wJ4sI9yKooSI+tOfGZ+BsD1XV5/CW17X1GULYaG7CpKCtGJrygpRCe+oqQQ3aSzBfnC51bWb9QDH/hwaf1GygWFPvEVJYXoxFeUFKITX1FSiNr4PRC3bb1ZiPq5dG1g66JPfEVJITrxFSWFbAlV/0JVsaNy9KnHOuV6w06YXyyKDGgiof3V198WaSxV5y9M9ImvKClEJ76ipBCd+IqSQhK18ZdnXsGzhz4MAHjm/GesukbrxlB9nHj6dKe8MFu16va969UNSrg1qIlD7DJZ+yusVgMOyfNB7fj0oU98RUkhOvEVJYUkquovNZbxnbPPAACe/cc3WHX5or8o1SWj2l49MtEpF2/eabWT5sKL3zll1S0vmj7+5c0/8h2ryeFMjiN/+0qn/Lbbu+YZjY3f2/8F6/qu/7etU/7Kp6esumzW/Ja/89Z7O+Vf/x+/Y7U7NfJrMUqobDX0ia8oKUQnvqKkkOQj97wTYt/8Dv+Dd9xTZGUEmuTpv7NV9r03X94pv/GtF/v238JNAWO7gxuefOxl00fLCOWq4r/14Ac65d/+0P/27c+FxQfNZf2Pzj30Z+fElfvbbfr46K+8p1NeXLSjH7Nn/2un3LziN0PLqFwY6BNfUVKITnxFSSE68RUlhRCzjwHdB8Z3VPiWn7963XaZnPN75CNiJutvjwd9rHM/nu+Ul+ZrVp203WfPLlt10iUoB7juX11mtav/wLzvX+z9Cavu597zzk65VCpadaWS2VlXyJvlF3ZuAAsZ3c85P7/UKY+NDXXKd7zntxGWP37kZOi2yubi3l/chxPPH/GfGB6hn/jeUdnfJaJHvesriOgJIjpBRF8iosJ6fSiKsjnoRdW/B+3DMlf5BIBPMvOVAKYB7I9TMEVR+kcodx4RXQrgpwH8PoBfp7bP61YAq36rhwH8DoDPdO2gW58ZWxvJF/zdV35q+w9fOGddlypCPXbe02y0RIemeObkvNXuxp27jIyTI1bd4VmzCejNEyZ6bv+//rdWu2Ixb2Qq2opQVrjpXNehlPHk1Bn4US4bE2GoYm+wmToz0ymvVI0ZU1+cteUQfTSbLavuwJ0XdcoHv2FHBioXBmGf+H8I4DcArP6FbAMww8yrW8FOAvB3zCuKsqlYd+IT0c8AmGLmp6IMQEQHiOgIER2prfS+ZVRRlPgJo+rfCOBniejdAEoARgF8CsA4EeW8p/6lALruVGHmgwAOAu1V/VikVhRlQ6w78Zn5AQAPAAAR3QLgXmb+IBH9JYD3AvgigLsBHFqvr0yGfHfh/eAZY0u69nkmKxUTU3nuxwtWu4mLh+DHzuUx0x+ZPnZvs23wat1oJU22FaI3jo53yiuiXTZrt8tmzPUaO17Y065tnRXrHrt3Gzv7xRft0ORm08hfq9la1J49JlT5pZde75S/9rXft9pNTpj70WrZckCIfPMdRo7/9X/U3r9Q2EgAz31oL/SdQNvmfzAekRRF6Tc9bdJh5scBPO6VXwJwQ/wiKYrSbxLdnVdbaeDk8fMAgBUZBQdgaUFE0DmqvoyYu6ZiVNRtpTGrXf1ss1PePm6r/ZUR40ZrCBW70bSaoSGi4lbqtppeE43v/U0TtpDJ2IqTNFVklB3guvPssXN5mRPfvO/sOdvlWKmYe7V9+6hVt7xs8hDOL5gdedeO2+1AUi4nMpCNYI9//b93ysegXChorL6ipBCd+IqSQhJV9ZsNxuy59gaWRs1eSX5z2ayYuxuH5ppGfR0dMpFqrYCdOIsrtimxsGzUY7kK33RU8YxQews5O5qwVpd2gf/YGbE6XyoXfOuyTmpsuarPMPdnecVOI14omPctLdkJNvI5U/fma+3NQxbSHFlzH811Nm/uwdXNz1mtjvGH/ftXNjX6xFeUFKITX1FSiE58RUkhidr4Q9kcbhhtR4Kdm12yKwtiJ5xjc46Iy6kZE63nZhsYGjZ9MNyIOWMn110fnkDau798z/ttEYvG3i2VzFpDzoncGxmtmP6cofLCPh8asnfW1etmHSID/52GMtKuXrMHaDTNdVXszisV7KQf8va4CU1qdbNukC8Yl2mzaSctuTrzUKd8rPUhKFsHfeIrSgrRia8oKSRRVb/FjKWq52YrDlt1c9NnO2U3x9yK2Iiyfcyo0a4rbmZuznds6SqTb/ule/6d1W50xET8DQ3bqrjMg5cTeQGHhytWO7nnJV+yXYLFkknSwWy7NDPIdq2r1Wx3Xr0uk2g0nTpzr+o1I2+tbo8lgwQbDbuOhB3QEGq/G6HYEhF+V/OfW3XH6JegbF70ia8oKUQnvqKkEJ34ipJCErXx640Wpqbb7jhmJ4nGaLlTdne0Sdt6RYTNujb+kAiPbThJLn7+bnOO3JhwtxVL9m9fuSJcdiJpJgDkhRx54R5z3W1DFSOHm1S01RLyO3Z3sWj6rEnXHtnrBI1mXZTtr7BWNXXlkrwfthwlEslCMk4fDeHOy5t7kM05fy5ih9/yvJ0Q5KrWn3XKxzP/EcrmQp/4ipJCdOIrSgpJVNXPZICiF7mWd3a+nZ836qW7W0xGxs3VMr7tPnD3HZ3y8FDZqitXMqJsPva2bdudsUyfeWf3nFT15a61YsCZAC3H5LDGytumRFP4AbPCXdhwIg1Z5NzLOeq3zPEnPX2Nun0cWLVmzICyc5RXsWh2StYbJsKyVrMj90iYIE22VX1pnlzFBzvl43QAyuDRJ76ipBCd+IqSQpJNxNFizC21o9CI7N+cmog4cxNs3HHXzZ3ykFDhR5yIuVGxWj88bKv6lUpRtDObeXIZW40u5k27NWmzC0aNlqaK+1laLfNZCLYZ0IJZdS8WJ+BHs27y7LleDhZqdL1hq9gkg/wyxnRotWw1PUMmB18+Z5scLeFxKRVM9GIddh9yo0/eMVuQMe/jpjEzrsFnrWYvtP4DlOTRJ76ipBCd+IqSQnTiK0oKSdTGJyIUPZfYzIKdJPLWn76pU3YTVMijoGWSC9dlJ98nj5IGbLu+Uhb2aMu28aXt7tqtJFx9lYoY28kIsrRgbOtiybnFbNxoa9J1snGdNcU6Qctp2WyaukbdljGbkUk6zHpCIW/fDxn1ODtvH6E9MmzvnAxDJmN/Z42GWWyoiO9lecleJ3hTziTwPNrQ5J1JEWriE9ErAOYBNAE0mHkfEU0C+BKAPQBeAfA+Zp7uj5iKosRJL6r+u5h5LzPv867vB3CYma8CcNi7VhRlC7ARVf8uALd45YfRPlPvvqA3lIfKeMs79wIAKhVHnbfUdDsX/dioSY4h31dwIuZGRBKNsqNiDwl3HlpCBXZO781ljOqcydm/iyWx+UYmoSBHZy9JU4LdjS3yws47KI+uksk33BN35ZUbTZcR5khGHNclzQMAaAiTIwP7DIJs3txjaXLUGnZCkJHhyU651XQzIEqBTV3FMeOWloyr7y2lL1h131/5gH+fyoYI+8RnAN8koqeIOjGXO5l59RzmUwB2xi6doih9IewT/yZmfo2ILgLwGBG9ICuZmYnc514b74fiALA2qEZRlMEQ6onPzK95/08B+Crax2OfJqJdAOD9P+Xz3oPMvI+Z98n94YqiDI51n/hENAQgw8zzXvkOAL8H4BEAdwP4uPf/ofX6ymYzGBlpP/Vdl11FuN9GRu0jrgtyJ5ywycfG7KOfS6KuXLbdXEURbsst0851c0kDulixf6iqVWPj5gtGe1mYt5N8VkrGHbZUtV1lknJxxLpeWVn2aWmvZawIOSqVcasunzdytRoiYUfdVshadbO+0Mr4J+yUSyBDZVveuTmTIDWXs+9VUawTyPtWKtrfO4sdidXqolV3ReNPOuWXcx+BEh9hVP2dAL7qLTDlAHyBmb9BRE8C+DIR7QfwQwDv65+YiqLEyboTn5lfAnBdl9fPAbitH0IpitJfEo3cy2azGPXUeDeyrizyzbuJLWTb0QCXXUn0IfP0AUBLZKXIihxzVLB3+Eldv7oyb9XURX5/mdtuqGSrwMt1O5+gRHrVVlq2ai/ddnkRCXfnT73Favd3//C8ucg4ZsCSUeFlBJ7MowcAjYa5j5S1k4XMzp7rlC+6aLcZiux21rkAzo7K+QVj/kxMbOuUpRvUpeWcMyB7vCZjdvXpjr6No7H6ipJCdOIrSgrRia8oKSRZGz+XxeS29rHLGdj2nNw9194LZJD2elHkupc2PQDkRIiqmyhTkq8YN2DTcSFlcsayLORt+79eM3ZrRmTnCWvTA0Bd2Nq5guO2LIqQYLkWULfvh8xQ1Gy4SS5NnTxO2z2nT2YCcm43RoaMXDXhimtm7NDesrW2Yfdfq9ltV1l0XJ8ZEnn7ndDkBsxny4ksQdc0NIvPRtEnvqKkEJ34ipJCklX1iVAptd1U7g48mbjBPXZaJtwol4ybyzmdCuWSed/Sin/EXKbqnwe/VPRPQkFZM+DKinGblUr2HoRa3XyWTMZJ5iFkLpdtVZ/J6NyLARF/sk9X1a82zG69vNhdWHLCpZsB+f4bwvVZXTGmUD7v7FYUx49lMu5OSXMfFxf9jy8vD5s/QTdJBzfMzZL9u7syr6mZZB4vtDSZRxj0ia8oKUQnvqKkkGRz7mWocwJtq2mrdSMjMpeereoXC4Wu5XzBFn+56q9SVpzoulXKFXusuTmTPSzrHPNVtdR78z6p2rs0mk7yirFLOmV2ct03RP6/5WUT1bd71+WOHM92yrmcbS60RC49a/XfWblfmDefpeicCjwvVt5HhcpOGSe/P5vnRs7xgEi3RBXmHrj3NIiJcZPoY2b2vJFpzN6YtLxivCpvGfm8Vff96gdDj5cm9ImvKClEJ76ipBCd+IqSQhLOqw9kvci4UtF2gQ0PGVvSPUK7WDC78+Sx0CtVN1mlMWRHR2w7MCtcYCz2fc0K2xFor0OsUqvZu+eyYuwgu14e3+3uRWs1TURbrW7LXxaRfDt2XNQpr9Ts6EJpaS8s+ufEl9F6Lef8PZlXv+wk2FhYNOscQ3INxAnGazZM/+75gRmRqESuQiy7n6Uh7mnD/ixDIqHJxJjZ4bfiHPktP+fcgv19vqn4UKd8tPUhKG30ia8oKUQnvqKkkMSP0FrdWDPkRK0VxYabvJNEQ6r0zZYxA0bH7Cg7qVbLzR9tjGq7uGgSbGSdzTzlslFtF5ds1XN4dFenPD/34055ZHjMaiddT5XKNkRhcdGoxJNj2626FRFNV3Qi8uSR2jI6Lz9i34+S3BDUcjbwiPctCbeidWwYgEbDmFbcdOyArDxGXCY3sdX0Sr67mxUAFpfN9yTdsfW67Qbdts24SM9Pn7LqlmvG1femwkOdctrVfn3iK0oK0YmvKClEJ76ipJBEbfxMhjrHRru7xWQSjeUl281VEKG54+PG1nNMU+SL4iy3up0o89y0yQE/PGT6yBds23e5at43MnKRVcdsXHhyJ2BtxbZvL7n8hk75/NQxq67ZMDZuzllfkHLNzJt1AnfnmyTjJK+oy915Yq3E3Y23II7Gzo5NWHXS9SedgO4uu1ZL7KgcstdbssKlyWTkyGTsZ82y+J7GR+y1jHMzpztlIrFmsMZJaq4nJ3ZZNeenX++U5brJlcWDVrsTmQNIE/rEV5QUohNfUVJIsqo+ZTrHS2WdI6iXlo167+bEl3nf5Y6zQtF2lUn1/tz0mTVjr1Iqm2QexLYcQxWjbjKco6VFxJh8X8aJWpubfqlT3nWJLeOp14y7KZt1dsUtGFV0fNzkBTx19lWrnbwHTjp7q08r554TuSdz2DfqtqkyLNyT1aowTZy/Fmk+1Bq2i606Z95XEmbA6Jitiq8si0g757NI1X9Z/H00HNfhski6Ui7ax6pJE7LeMAO4OQGvLBjVPw1qf6gnPhGNE9FXiOgFIjpKRO8gokkieoyIjnv/T6zfk6Iom4Gwqv6nAHyDma9B+zitowDuB3CYma8CcNi7VhRlCxDmtNwxAD8J4EMAwMw1ADUiugvALV6zhwE8DuC+oL6YW6h76jKzvVKdzRm1Uaa4BoDRYaO+lUpmpb3urNxPzxr1Xh6TBQATk2bTDomxh7fZqufMOaNW58mJVBOr+twyv5lN2GpuRiygn5myj66SkYKzs9NW3eTYTnMhFq6bThaN4aFxUWdHwtVqRpbhYdMul7VXwlti09Kao6uEWdAQOf12X3ql1e706Vc6Zde0sqMNxfdJ/kdouXkGh4tG/mLFeGwaC6etdi2xWahK9t+E3JBVEDkC61X7b2xkyJg3V8x92qp7Of+ffGXeqoR54l8B4AyAzxHRd4noz73jsncy86qv5BTap+oqirIFCDPxcwDeCuAzzHw9gEU4aj2396Fyl/eCiA4Q0REiOjIzu9itiaIoCRNm4p8EcJKZn/Cuv4L2D8FpItoFAN7/U93ezMwHmXkfM+8bHxvq1kRRlIRZ18Zn5lNE9CoRXc3MxwDcBuB579/dAD7u/X9o3dGIkPWOnmo5Ry4VhK9o++RlVl1T7AKri+Oqpp2dWBnICL9xp87YtEPbLu6UZ86dtNpx3dj/2RF751hrydiPnLXt+jiQuehKTaZfAAAF2klEQVSnF4zNvH37DluO1olOOeOsZcgkINJWrzsuMGlp11Zst2WpbBw0FXFE+fKiHVEpI/yaThildPWdP2eeCdu22xahTGiSzdrrPrOL5rju7ReZo8KXxesA0BDnlBWLJasuL1zBdXF2Q7lit5N+0YlRO4IQwua/UOz9sH78XwXweSIqAHgJwIfR1ha+TET7AfwQwPv6I6KiKHETauIz89MA9nWpui1ecRRFSYJEI/cARsvLi1fI21FrY8L940aSVeszXXuTrisA2LXTqMRZJxFHXSSMmz7zIyNRw1YvhyeMKro8Z5sSNtJFZa9rVirGRKgu27n5zk8bNfWfX/Emq+7kqZc75ZJQsd3wvI/ea06H/fSnHrbqWiKfvX1ari29TKJBTo5DZmMItESufzfarZAviHLRqjv5mnGLXnyxNFUcQbouCa+tWlww30WhaLsEZ2ZElKCj6ufywnTLmo1VTecY4/kl8zc2OjRp1ZVE/sDLV/7YqvtR8Vf9xN/UaKy+oqQQnfiKkkJ04itKCkk22Sao47IZcxJIZtjY5DPzr1t1Mqf61Blj6+3audtqV6saezrneGtaTWMxnjtn+ti+/RL4UXfWEGTI7vioCfFkx4AuFY29W636598Por5k7Ng9111r1f3T33/TyOScv1cUH3ylaurcXB4kfvPdnXsNcZ5Ak437tFB0E3a0upYB270ny4vzdjIPeY5Bs2HLkRM7OAlGpnLpYqtdbcisPRQLdpj1gkisWhEJXpstOwy6VBRJVlfssN8hkeiz4awNXEV/2ikf51/GVkGf+IqSQnTiK0oKIVdN7etgRGfQDvbZDuDsOs37zWaQAVA5XFQOm17leAMz71ivUaITvzMo0RFm7hYQlCoZVA6VY1ByqKqvKClEJ76ipJBBTfyD6zfpO5tBBkDlcFE5bPoix0BsfEVRBouq+oqSQhKd+ER0JxEdI6ITRJRYVl4i+iwRTRHRs+K1xNODE9FlRPQtInqeiJ4jonsGIQsRlYjo20T0PU+O3/Vev4KInvC+ny95+Rf6DhFlvXyOjw5KDiJ6hYi+T0RPE9ER77VB/I0kkso+sYlP7cPP/gTAvwFwLYD3E9G1we+KjYcA3Om8Noj04A0AH2PmawG8HcBHvHuQtCxVALcy83UA9gK4k4jeDuATAD7JzFcCmAawv89yrHIP2inbVxmUHO9i5r3CfTaIv5FkUtkzcyL/ALwDwN+I6wcAPJDg+HsAPCuujwHY5ZV3ATiWlCxChkMAbh+kLAAqAL4D4G1oB4rkun1ffRz/Uu+P+VYAj6KdFWwQcrwCYLvzWqLfC4AxAC/DW3vrpxxJqvq7AcizoE56rw2KgaYHJ6I9AK4H8MQgZPHU66fRTpL6GIAfAJhh5tVdKEl9P38I4DeAThLGbQOSgwF8k4ieIqLVM7SS/l4SS2Wvi3sITg/eD4hoGMBfAfgoM1vb1ZKShZmbzLwX7SfuDQCu6feYLkT0MwCmmPmppMfuwk3M/Fa0TdGPENFPysqEvpcNpbLvhSQn/msAZPrcS73XBkWo9OBxQ0R5tCf955n5rwcpCwAw8wyAb6GtUo8TdQ6zT+L7uRHAzxLRKwC+iLa6/6kByAFmfs37fwrAV9H+MUz6e9lQKvteSHLiPwngKm/FtgDgFwA8kuD4Lo+gnRYcCJsefIMQEQF4EMBRZv6DQclCRDuIaNwrl9FeZziK9g/Ae5OSg5kfYOZLmXkP2n8P/5eZP5i0HEQ0REQjq2UAdwB4Fgl/L8x8CsCrRHS199JqKvv45ej3oomzSPFuAC+ibU/+lwTH/QsArwOoo/2ruh9tW/IwgOMA/hbAZAJy3IS2mvYMgKe9f+9OWhYAPwHgu54czwL4Le/1fwbg2wBOAPhLAMUEv6NbADw6CDm88b7n/Xtu9W9zQH8jewEc8b6brwGY6IccGrmnKClEF/cUJYXoxFeUFKITX1FSiE58RUkhOvEVJYXoxFeUFKITX1FSiE58RUkh/x8TJIdQQGagdwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "obs_ = np.asarray(obs[:,:,:3]/255, dtype=np.float32)\n",
    "# print(np.shape(obs_[:,:,:3]))\n",
    "# print(obs_[:,:,0:3])\n",
    "plt.imshow(obs_[:,:,0:3])\n",
    "y = cv2.cvtColor(obs_[:,:,:3], cv2.COLOR_RGB2GRAY)\n",
    "print(y)\n",
    "np.concatenate((y, obs[:,:,3]), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward:  -0.10141563415527344\n",
      "Total reward:  -0.262847900390625\n",
      "Total reward:  -0.6770915985107422\n",
      "Total reward:  -0.9566812515258789\n",
      "Total reward:  -1.2073335647583008\n",
      "Total reward:  -1.4364309310913086\n",
      "Total reward:  -1.6334123611450195\n",
      "Total reward:  -1.8068876266479492\n",
      "Total reward:  -1.950465202331543\n",
      "Total reward:  -2.0539817810058594\n",
      "Total reward:  -2.195737838745117\n",
      "Total reward:  -2.404491424560547\n",
      "Total reward:  -2.8385095596313477\n",
      "Total reward:  -3.1186342239379883\n",
      "Total reward:  -3.364840507507324\n",
      "Total reward:  -3.577943801879883\n",
      "Total reward:  -3.7570695877075195\n",
      "Total reward:  -3.9056196212768555\n",
      "Total reward:  -4.025485038757324\n",
      "Total reward:  -4.1314697265625\n",
      "Total reward:  -4.215169906616211\n",
      "Total reward:  -4.282061576843262\n",
      "Total reward:  -4.338621139526367\n",
      "Total reward:  -4.477829933166504\n",
      "Total reward:  -4.917474746704102\n",
      "Total reward:  -5.176027297973633\n",
      "Total reward:  -5.412221908569336\n",
      "Total reward:  -5.609671592712402\n",
      "Total reward:  -5.7818498611450195\n",
      "Total reward:  -5.928816795349121\n",
      "Total reward:  -6.0518999099731445\n",
      "Total reward:  -6.1535539627075195\n",
      "Total reward:  -6.23725700378418\n",
      "Total reward:  -6.307980537414551\n",
      "Total reward:  -6.371119499206543\n",
      "Total reward:  -6.432916641235352\n",
      "Total reward:  -6.500382423400879\n",
      "Total reward:  -6.626302719116211\n",
      "Total reward:  -6.823624610900879\n",
      "Total reward:  -6.957853317260742\n",
      "Total reward:  -7.0826416015625\n",
      "Total reward:  -7.191169738769531\n",
      "Total reward:  -7.2936553955078125\n",
      "Total reward:  -7.379700660705566\n",
      "Total reward:  -7.446815490722656\n",
      "Total reward:  -7.500199317932129\n",
      "Total reward:  -7.5426435470581055\n",
      "Total reward:  -7.5807952880859375\n",
      "Total reward:  -7.61616325378418\n",
      "Total reward:  -7.695138931274414\n",
      "Total reward:  -7.827785491943359\n",
      "Total reward:  -7.935085296630859\n",
      "Total reward:  -8.04060173034668\n",
      "Total reward:  -8.140327453613281\n",
      "Total reward:  -8.244218826293945\n",
      "Total reward:  -8.34981918334961\n",
      "Total reward:  -8.444025039672852\n",
      "Total reward:  -8.540401458740234\n",
      "Total reward:  -8.6282958984375\n",
      "Total reward:  -8.711292266845703\n",
      "Total reward:  -8.805448532104492\n",
      "Total reward:  -8.938125610351562\n",
      "Total reward:  -9.307254791259766\n",
      "Total reward:  -9.546531677246094\n",
      "Total reward:  -9.77669906616211\n",
      "Total reward:  -10.005464553833008\n",
      "Total reward:  -10.219648361206055\n",
      "Total reward:  -10.419168472290039\n",
      "Total reward:  -10.614810943603516\n",
      "Total reward:  -10.797290802001953\n",
      "Total reward:  -10.969335556030273\n",
      "Total reward:  -11.143768310546875\n",
      "Total reward:  -11.317167282104492\n",
      "Total reward:  -11.521337509155273\n",
      "Total reward:  -11.893482208251953\n",
      "Total reward:  -12.116878509521484\n",
      "Total reward:  -12.332963943481445\n",
      "Total reward:  -12.539228439331055\n",
      "Total reward:  -12.737665176391602\n",
      "Total reward:  -12.909889221191406\n",
      "Total reward:  -13.072263717651367\n",
      "Total reward:  -13.224529266357422\n",
      "Total reward:  -13.394309997558594\n",
      "Total reward:  -13.594879150390625\n",
      "Total reward:  -13.878301620483398\n",
      "Total reward:  -14.0474853515625\n",
      "Total reward:  -14.188362121582031\n",
      "Total reward:  -14.333845138549805\n",
      "Total reward:  -14.462709426879883\n",
      "Total reward:  -14.575054168701172\n",
      "Total reward:  -14.687503814697266\n",
      "Total reward:  -14.779983520507812\n",
      "Total reward:  -14.83657455444336\n",
      "Total reward:  -14.880891799926758\n",
      "Total reward:  -14.897754669189453\n",
      "Total reward:  -14.91189193725586\n",
      "Total reward:  -14.927936553955078\n",
      "Total reward:  -14.979362487792969\n",
      "Total reward:  -15.138774871826172\n",
      "Total reward:  -15.2679443359375\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "net_reward = 0\n",
    "\n",
    "for i in range(100):\n",
    "    action = env_serial.sample()\n",
    "    obs, reward, done, info = env_serial.step(\n",
    "        action)\n",
    "\n",
    "    net_reward += reward\n",
    "    print(\"Total reward: \", net_reward)\n",
    "# env_serial.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'life'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96d903fe8c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'life'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'life'"
     ]
    }
   ],
   "source": [
    "print(info['life'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_rl_37",
   "language": "python",
   "name": "conda_rl_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
